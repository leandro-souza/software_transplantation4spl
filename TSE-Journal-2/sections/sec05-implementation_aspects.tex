\section{Implementation Aspects} 
\label{sec:implementation_aspects}

This section presents how the proposed tool was implemented in order to provide a solution for automated the reengineering process of existing systems to SPL. It gives more details about some technical aspects of \autoscalpel tool implementation. Moreover, it presents some challenges found in the implementation process that are enumerated together with the solution implemented.

Implemented in  C and TXL, \autoscalpel comprises 40k SLoCs, of which 23k is C and 17k is TXL code. It requires as inputs for each transplant interaction an organ’s entry point, an insertion point in the host and all C source code and header files in the donor and host's sub-directories. The developer also must supplies test suites that guide the search for donor code modifications required to make it fully executable (and pass all test cases) when deployed in the product base. Given these inputs, \autoscalpel transfer all the code in the donor that implements the target functionality and incrementally produces a new product on a product base. 

The \autoscalpel is an ST tool, which reuses features from multiple systems for transplantation and genetically combines them into one or more product base to attend specific application domains. This is a challenging application of transplantation because code from multiple systems are unlikely to even compile when it is re-located into an unrelated foreign product base without extensive modification, let alone execute and pass test cases. Moreover, the extraction of the code also involves identifying all semantically required code and the successful insertion of the code organ into the host requires nontrivial modifications to the organ to ensure it adds the required features without breaking existing functionality.  

To make this possible, our tool incorporates a set of already consolidated reengineering, search-based and engineering practices into the ST process such as (i) \emph{program slicing} \cite{Binkley:2014:OLP:2635868.2635893} to automate the location; \emph{genetic programming} and (iii) \emph{testing}  to features transformation; and (iv) \emph{code clone detection}, (v) \emph{Program differencing} to handle code duplication and organ collision problems.

To  achieve  the  transplant  of  multiple  organs we had to implement solutions to the new some challenges associated with the necessity to compose multiple organs into a single code base.

\subsection{Handling Preprocessor Directives}

The preprocessor conditionals (cpp) found in large systems often have a set of complex Boolean definitions that encode configuration dependencies, and complex nesting to allow code sharing between configurations. From the maintenance point of view, compile-time configurability brings big challenges~\cite{Tartler2011}. On of them is the necessity of the configuration model (as presented to the user) and the configurability that implemented in the code level have to be kept in sync, which, if performed manually, is a boring and error-prone task~\cite{Tartler2011}. Moreover, once a configuration is defined and a new product is generated, the unnecessary portion of the code (consisting of unselected configurations) can be considered dead code. Thus, ideally would remove dead code, keeping just the code required one by the current system configuration.

\textbf{Solution}. As our proposed is based on construct products on a product base we had to implement a preprocessor directives handler, also used to remove unwanted directives in the organs. This implementation also fix one of the initial algorithm limitation, its default C grammar’s inability to properly handle preprocessor directives. Our solution \autoscalpel uses the command line tool \emph{unifdef}\footnote{http://freshmeat.sourceforge.net/projects/unifdef}  which selectively processes conditional directives. By receiving as input a list of all possible configurations and the guidelines to switch between them, it removes from the donor systems both the directives and the additional text that they delimit, while otherwise leaving the required portion of code defined by the current configuration file, keeping unchanged the source code structure belonging to the organ. 
    
Although useful, only select processes directives is not the best solution, because it does not really understand programming language's lexical and grammatical syntax. For example, \emph{unidef} does not handle defined or \#elif preprocessor directives or handle more complex problems, such as determining that both sides of a conditional assign the same value to a preprocessor variable. To handle this weakness, \autoscalpel has also been implemented in TXL~\cite{Cordy2006}. From it, \autoscalpel becomes able to more reliably remove such dead code and compilation directives, by removing unused configurations.
%============================

\subsection{Multiple-file Slicing} 
    
The extraction of each selected organ captures a considerable amount of code not confined in a single file or library. Thus, an important issue, which must be considered during organ extraction, is how to organize the code belonging to a particular organ in terms of its file structure. Although it is possible to implement modifications to organ's files structure and even introduce a new one, we have chosen to maintain it in its original form, as implemented in its donor, without any redesign of the system besides those ones performed by GP during GP-refinement. This is justified when we consider the inherent complexity of the process, which often decreasing readability and maintainability while introducing the potential for additional programming errors. 

\textbf{Solution}. Program slicing technique implemented in $\mu$scalpel was extended to produce a multi-file organ. We had to implement a multi-file slicer that computes slices in multi-files, keeping the original file structure of the features rather inline all their functions calls in a single file. Thus, each slice constructed includes either the files which each statement has been originally captured, necessary to produces an organ composed by multiple files. Producing a multi-file organ became it more self-contained and more understandable, facilitating future maintenance of the organ in the new product. Additionally, by computing multi-file organs, we avoid code duplication by handling dependencies between organs when transplanted from the same donor.

%=====================
\subsection{Code Duplication} 

As detailed in stage five of our approach description (\ref{organ_implantation}), an organ into a donor program may share common portions of code with other organs. This characteristic creates a high-degree complex interaction which must be considered during autotransplantation process in order to generate a product line without code duplication.

\textbf{Solution}. To automated the comparison of features, we implemented in \autoscalpel a code clone detector based on the \emph{NiCad}~\cite{Roy2009}. We combine \emph{Clone detection} and \emph{Program differencing} techniques for the purpose of comparing features and avoid the code duplication and overlapping of features elements during the implantation process of multiple features. Thus, \autoscalpel can handle feature dependencies using a context-free parsing mechanism implemented in TXL. 

The code clone detection technology provides an intuitive mechanism to include code only when a new element has not been selected in previous organ transplantation. In this case, \autoscalpel checks if there is some element into the organ that is already presented at a list of elements transplanted. Once that potential code duplication is found, it is analysed using program differencing techniques implemented to execute the \emph{GNU DIFF} commands.

The program differencing tool, diff, used to identify individual textual differences at a line level, even that it reflects changes in the organs already transplanted. Thus, \autoscalpel identify what changed between the organ and host code while carrying out peer code reviews, resolving parallel edit conflicts. 

Although useful, this is not enough solution yet, because a line-by-line code comparison does not really understand programming language's lexical and grammatical syntax. For example, \emph{unidef} does not handle more complex problems, such as determining high-level software changes such as refactorings~\cite{Fowler1999}, \cite{Chikofsky1990} and crosscutting modifications~\cite{Kiczales1997} often consist of a group of changes that share similar structural characteristics.

We exploit the benefits of TXL~\cite{Cordy2006} to identify and compare potential syntactic code duplication, as shown in Figure~\ref{fig:code_clone_analysis}. Thus, the clone detector finds exact clones over arbitrary program fragments in organ and host source code by comparing abstract syntax trees. It checks if a specific code element is already present in our beneficiary by looking for \emph{name collisions} in organ and host abstract tree. From this, we may tune the existing code of potential clones to introduce additional line breaks such that potential variances within statements and other structures can be accurately inserted by using sub-abstract tree comparison. 

Our solution complements the feature aggregation process though GP by locating and dependency handling when the reengineering process requires the transplant of two or more features from the same donor. Using a line-by-line and semantic code comparison, we can accurately determine which elements are shared between the organs transplanted, preventing shared elements from being inserted into the host again. 

\subsection{Precise Call Graph Construction}

Call graph construction is an important part of the program slicing process implemented in our solution since it makes the set of functions that may be the target of a given call explicit. For the construction of the call graphs, $\mu$\textsc{scalpel} uses \emph{GNU cflow}, and thus inherit its limitations related to function pointers and such as its stack limit and large output graph production which precludes parsing large programs. If the output graph is large, it can be time-consuming and expensive for TXL programming to construct and manipulate the program. The construction of a more precise call graph more precisely approximates the over-organ to the real organ, at a reduced effort and time to compute, and take up less amount of memory.  
\textbf{Solution}. Unlike initial transplantation tool, \autoscalpel is implemented with a more precise mechanism of call graph generation by using \emph{Doxygen}\cite{Doxygen2018}, a source code documentation generator written in C++. It able the production of individual call graphs which means that for each procedure, the graph contains a separate node for each call stack that procedure can be activated with. This allows the more precise call graph obtainable and individual identification of all program elements relevant to a feature—it fixing one of the initial tool problems such as its stack limit which precludes parsing large programs. 

\subsection{Automatic Organ-host Interface Construction} 

Harman et al.~\cite{Harman2013} proposed that one steps to achieve AST would be the automatic construction of an organ-host interface, responsible for providing access to the organ from and within the host.  In addition to the benefits of encapsulation that this interface can provide, its automatic implementation also frees developers from the burden of writing the code to connect up and convert host data structures into organ parameters. 

\textbf{Solution}. We have introduced an \emph{organ-host converter}.  \autoscalpel inserts a call to this converter at the implantation point in the host. Then, \autoscalpel~constructs an organ-interface which is filled automatically by GP during the organ adaptation process. At the interface, GP tries to bind the parameters at the implantation point with variables in the organ's interface signature. GP synthesizes a call to the extracted organ within the host. The interface constructed will be sufficient to allow the host to access the organ as a component at the code level and that its implementation will be hidden through encapsulation. In addition to the benefits of encapsulation that its interface provides, this converter also frees developers from the labour-intensive task of manually annotating feature entry points. 
